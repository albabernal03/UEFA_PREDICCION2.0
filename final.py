from bs4 import BeautifulSoup
import requests
import csv
import pandas as pd

years = ['2018-19', '2019-20', '2020-21', '2021-22', '2022-23']

def get_final_data(year):
    url = f'https://es.wikipedia.org/wiki/Final_de_la_Liga_de_Campeones_de_la_UEFA_{year}'

    response = requests.get(url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, 'html.parser')

    # Encuentra la tabla que contiene la informaci칩n de la final
    table = soup.find('table', {'class': 'collapsible collapsed'})

    if table:
        # Extraer la primera fila de la tabla
        rows = table.find_all('tr')
        first_row = rows[0]

        # Buscar los elementos relevantes en la primera fila
        team_1 = first_row.find('a', title=True).get_text(strip=True)
        team_2 = first_row.find_all('a', title=True)[1].get_text(strip=True)
        result = first_row.find('b').get_text(strip=True)

        return team_1, result, team_2
    else:
        print(f"No se encontr칩 la tabla en la p치gina para el a침o {year}.")
        return None, None, None

final_data = []

for year in years:
    team_1, result, team_2 = get_final_data(year)
    final_data.append([year, 'Final', team_1, result, team_2])  

# Escribir en el archivo CSV
with open('final.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Temporada', 'Fase', 'Equipo 1', 'Resultado', 'Equipo 2'])
    writer.writerows(final_data)

# Leer el archivo CSV
final_df = pd.read_csv('final.csv')

# Mostrar el DataFrame
print(final_df)

